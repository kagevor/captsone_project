{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88ea59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for data analysis and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import requests\n",
    "import io\n",
    "import ast\n",
    "\n",
    "# Import scikit-learn modules for machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Import geospatial data visualization libraries\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from branca.colormap import linear\n",
    "from folium import plugins\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc921f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset \n",
    "url = \"https://data.cityofchicago.org/resource/4ijn-s7e5.csv\"\n",
    "params = {\"$limit\": 1000000} \n",
    "response = requests.get(url, params=params)\n",
    "data = pd.read_csv(io.StringIO(response.text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaab99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the DataFrame to inspect the data\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36513eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types and missing values in the DataFrame\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d24e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baf135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics of the numerical columns\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd548ca",
   "metadata": {},
   "source": [
    "1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0b5bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column aka_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dbf3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['aka_name'] = data['aka_name'].fillna(data['dba_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0639b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column license_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77deb6f5",
   "metadata": {},
   "source": [
    "We noticed however that there are some restaurant with licence numbers equal to 0.\n",
    "\n",
    "handle new license numbers for rows with a license value of 0 or NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f233835",
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting id for new license numbers\n",
    "new_license_id = int(data['license_'].max() + 1)\n",
    "license_zero = data[(data['license_'] == 0) | (data['license_'].isna()) ][['dba_name', 'address']].copy().drop_duplicates()\n",
    "license_zero['new_license'] = [i for i in range(new_license_id, new_license_id+len(license_zero))]\n",
    "data = data.merge(license_zero, on=['dba_name', 'address'], how='left')\n",
    "data['license_'] = data['license_'].apply(lambda x: np.nan if x == 0 else x)\n",
    "data['license_'] = data['license_'].fillna(value = data['new_license'])\n",
    "data.drop(columns=['new_license'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c158e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column facility_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693afdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['facility_type'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a496bf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies_facility_type = data['facility_type'].value_counts(normalize=True)\n",
    "print(frequencies_facility_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532fc470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After analyzing the data, we observe that 'Restaurant' dominates the majority of the records, \n",
    "#making up approximately 68% of the dataset, and we use it to fill the missing values.\n",
    "\n",
    "data['facility_type'].fillna('Unknown Facility', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf65c2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b9a23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the frequency of each risk level\n",
    "risk_counts = data['risk'].value_counts(normalize=True)\n",
    "\n",
    "# distribution of risk levels\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(risk_counts.index, risk_counts.values)\n",
    "plt.xlabel('Risk Level')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Risk Levels in Chicago Food Inspections')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91565981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The occurrence of the \"All\" category is relatively small compared to the total dataset and does\n",
    "# not provide meaningful insights for our analysis. As the number of missing values is relatively small \n",
    "# compared to the total data size, and chosen to drop rows with NaN values  and the \"All\" category from the 'risk' column.\n",
    "\n",
    "data = data.dropna(subset=['risk'])  \n",
    "data = data[data['risk'] != 'All']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2667a0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991c7cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f33e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the ZIP codes table is the first table on the page\n",
    "zip_codes_df = pd.read_csv('zip_code_database.csv', dtype={'zip' :float})\n",
    "data = pd.merge(data, zip_codes_df[['zip', 'primary_city']], on='zip', how='left')\n",
    "data['city'] = data['city'].fillna(data['primary_city'])\n",
    "data.drop('primary_city', axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be8fc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in 'city' column with 'CHICAGO' where 'state' is 'IL'\n",
    "data.loc[(data['city'].isna()) & (data['state'] == 'IL'), 'city'] = 'CHICAGO'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde16d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['city']= data['city'].str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b3f055",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['city'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5ae5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['city'].str.contains('icago', case=False)) & (data['city'] != 'Chicago')]['city'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59e4af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['city'].str.contains('icago', case=False), 'city'] = 'Chicago'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af877089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1ed25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in 'state' column with 'IL' where 'city' is 'CHICAGO'\n",
    "data.loc[(data['state'].isna()) & (data['city'] == 'CHICAGO'), 'state'] = 'IL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ec850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['state'].fillna('Not Available', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21facf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['state'] == 'IL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a9aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'state' column\n",
    "data.drop('state', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0891486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb000c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['zip'].isna()].city.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b9aea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['zip'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d1a5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most frequent zip code\n",
    "most_frequent_zip = data['zip'].mode().values[0]\n",
    "\n",
    "# Fill missing 'zip' values with the most frequent zip code\n",
    "data['zip'].fillna(most_frequent_zip, inplace=True)\n",
    "\n",
    "\n",
    "# Convert the 'zip' column to string data type \n",
    "data['zip'] = data['zip'].astype(int)\n",
    "data['zip'] = data['zip'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a1edc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column inspection_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cef1c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspection Date to Datetime type\n",
    "data['inspection_date'] = pd.to_datetime(data['inspection_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f151a025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column inspection_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a793c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['inspection_type'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e02365",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['inspection_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766cf05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['inspection_type'].fillna('Unknown', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c7734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['inspection_type'] = data['inspection_type'].str.lower()\n",
    "data.loc[data['inspection_type'].str.contains('canvas', case=False), 'inspection_type'] = 'canvass'\n",
    "data.loc[data['inspection_type'].str.contains('licen', case=False), 'inspection_type'] = 'license'\n",
    "data.loc[data['inspection_type'].str.contains('complai', case=False), 'inspection_type'] = 'complaint'\n",
    "data.loc[data['inspection_type'].str.contains('task', case=False), 'inspection_type'] = 'task force'\n",
    "data.loc[data['inspection_type'].str.contains('kids', case=False), 'inspection_type'] = 'kids cafe'\n",
    "data.loc[data['inspection_type'].str.contains('out of', case=False), 'inspection_type'] = 'out of business'\n",
    "data.loc[data['inspection_type'].str.contains('reinspection ', case=False), 'inspection_type'] = 'recent inspection'\n",
    "# Suspected Food Poisoning replacements\n",
    "sfp_values = data['inspection_type'].str.lower().str.contains('food|sfp', regex=True)\n",
    "data.loc[sfp_values, 'inspection_type'] = 'suspected food poisoning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88b0b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_categories(keyword, target_category):\n",
    "  categories_containing_keyword = data['inspection_type'].str.lower().str.contains(keyword)\n",
    "  data.loc[categories_containing_keyword, 'inspection_type'] = target_category  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825ff879",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_categories('recent inspection', 'Recent Inspection')\n",
    "merge_categories('out of business', 'Out of Business')\n",
    "merge_categories('no entry', 'No Entry')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668e76db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['inspection_type'] = data['inspection_type'].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cea4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_types = ['License', 'Canvass', 'Complaint', 'Non-Inspection', 'Suspected Food Poisoning', 'Consultation', 'Tag Removal', 'Recent Inspection', 'Out Of Business', 'Task Force', 'No Entry']\n",
    "# Classify the rest as unknown\n",
    "data.loc[~data['inspection_type'].isin(known_types), 'inspection_type'] = 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a03f1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4ee6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing 'violations' values with 'Not Available'\n",
    "data['violations'].fillna('Not Available', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784114af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of 'latitude'  \n",
    "latitude_mean = data['latitude'].mean()\n",
    "\n",
    "# Fill missing 'latitude'  values with the mean\n",
    "data['latitude'].fillna(latitude_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d33e4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf9e262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of 'longitude' \n",
    "longitude_mean = data['longitude'].mean()\n",
    "\n",
    "# Fill missing 'longitude' values with the mean\n",
    "data['longitude'].fillna(longitude_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d634d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026322bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreating the 'location' column by combining 'latitude' and 'longitude'\n",
    "data['location'] = list(zip(data['latitude'], data['longitude']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe04a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b89d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data_prep.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91c8192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f37b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA (Exploratory Data Analysis) - Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e40189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset \n",
    "data = pd.read_csv('data_prep.csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame to inspect the data\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9aa83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA (Exploratory Data Analysis) - Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36277def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'zip' column to string data type \n",
    "data['zip'] = data['zip'].astype(int)\n",
    "data['zip'] = data['zip'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d06cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fun\n",
    "# creating a Word Cloud for the most common words in DBA names\n",
    "\n",
    "all_dba_names = ' '.join(data['dba_name'])\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_dba_names)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443cfff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Information from 'inspection_date':\n",
    "\n",
    "# Convert 'inspection_date' column to datetime format\n",
    "data['inspection_date'] = pd.to_datetime(data['inspection_date'])\n",
    "\n",
    "# Extract the year from 'inspection_date' and create a new column 'inspection_year'\n",
    "data['inspection_year'] = data['inspection_date'].dt.year\n",
    "\n",
    "# Extract the month from 'inspection_date' and create a new column 'inspection_month'\n",
    "data['inspection_month'] = data['inspection_date'].dt.month\n",
    "\n",
    "# Determine the season based on the month and create a new column 'inspection_season'\n",
    "data['inspection_season'] = data['inspection_month'] % 12 // 3 + 1\n",
    "\n",
    "# Extract the weekday from 'inspection_date' and create a new column 'inspection_weekday'\n",
    "data['inspection_weekday'] = data['inspection_date'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96b72a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe097814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualization\n",
    "\n",
    "# Number of inspections per year\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=data, x='inspection_year')\n",
    "plt.xlabel('Inspection Year')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Inspections by Year')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c8c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplot of inspections by year, segmented by 'result'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=data, x='inspection_year', hue=data['results'])\n",
    "plt.xlabel('Inspection Year')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Inspections by Year with Result')\n",
    "plt.legend(title='Result', loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e17ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplot of inspections by year, segmented by 'risk'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=data, x='inspection_year', hue=data['risk'])\n",
    "plt.xlabel('Inspection Year')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Inspections by Year with Risk')\n",
    "plt.legend(title='Risk', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cc1c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract violation codes from a textual list of violations\n",
    "def extract_violation_codes(violation):\n",
    "    # Split the violations and remove leading/trailing spaces\n",
    "    violations_list = list(map(lambda v: v.strip(), violation.split('|')))\n",
    "    # Find the dot (.) in each violation to extract the code (e.g., \"21. Food Contact Surfaces\")\n",
    "    violation_dots = [violation.find('.') for violation in violations_list]\n",
    "    # Create a set of unique violation codes to avoid duplicates per inspection\n",
    "    violation_codes = list(set([int(v[:idx]) for v, idx in zip(violations_list, violation_dots) if idx != -1]))\n",
    "    return violation_codes\n",
    "\n",
    "# Add an additional column with extracted violation codes\n",
    "data['violation Codes'] = data['violations'].apply(extract_violation_codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe082493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for plotting violation codes distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8199ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to merge all violation codes from the column into one flat array\n",
    "def merge_violation_codes(violation_series):\n",
    "    return [code for inspection_violation_codes in violation_series.values for code in inspection_violation_codes]\n",
    "\n",
    "# Function to create the histogram for violation codes\n",
    "def violation_counts(violations, max_violation_code):\n",
    "    counts, code_bins = np.histogram(violations, bins=np.arange(1, max_violation_code + 2))\n",
    "    return counts, code_bins\n",
    "\n",
    "# Function to create the violation codes distribution from the dataframe\n",
    "def violations_distribution(df, violation_column='Violation Codes', max_violation_code=70):\n",
    "    all_codes = merge_violation_codes(df[violation_column])\n",
    "    counts, code_bins = violation_counts(all_codes, max_violation_code)\n",
    "    return code_bins[:-1], counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0076fde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot stacked bars for violation codes distribution\n",
    "def plot_violations_stacked_bars(data, title, violation_column='violation Codes', max_violation_code=70, xticks=None):\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    plt.title(title)\n",
    "\n",
    "    results = data['results'].unique()\n",
    "    bars = []\n",
    "    total_counts = len(data)\n",
    "    \n",
    "    previous_counts = np.zeros((max_violation_code,))\n",
    "    \n",
    "    # Create stacked bar chart\n",
    "    for result in results:\n",
    "        bins, counts = violations_distribution(data[data['results'] == result], violation_column, max_violation_code)\n",
    "        percentages = counts / total_counts * 100  # Calculate percentage for each violation code count\n",
    "        bar = plt.bar(bins, percentages, bottom=previous_counts)\n",
    "        bars.append(bar[0])\n",
    "        # Accumulate counts for positioning the next stack\n",
    "        previous_counts += percentages\n",
    "\n",
    "    if xticks is not None:\n",
    "        plt.xticks(np.arange(1, max_violation_code + 1), xticks, rotation=40)\n",
    "    else:\n",
    "        plt.xlabel('Violation code')\n",
    "\n",
    "    plt.ylabel('% of inspections with violations')\n",
    "    plt.ylim((0, 80))\n",
    "\n",
    "    plt.legend(tuple(bars), tuple(results))\n",
    "    plt.grid(True, axis='y')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7450228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_violations_stacked_bars(data, 'Distribution of most common violations')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cec90d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus only on passed inspections\n",
    "passed_inspections = data[data['results'] == 'Pass']\n",
    "plot_violations_stacked_bars(passed_inspections, 'Passed inspection violations distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682bef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus only on failed inspections\n",
    "failed_inspections = data[data['results'] == 'Fail']\n",
    "plot_violations_stacked_bars(failed_inspections, 'Failed inspection violations distribution')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2202bc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the above array creates mappings between original codes and generalized categories\n",
    "def create_mapping(codes):\n",
    "  mapping = {}\n",
    "  for new_code, category_codes in enumerate(codes):\n",
    "      for old_code in category_codes:\n",
    "          mapping[old_code] = new_code + 1  # new codes starting from 1\n",
    "  return mapping\n",
    "\n",
    "# Function to transform array of original codes into our categories\n",
    "def encode_violations(violations, mapping):\n",
    "  encoded = []\n",
    "  for violation in violations:\n",
    "    encoded.append(mapping[violation])\n",
    "  return encoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b7ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_codes = [11, 12, 13, 14, 15, 17, 23, 26, 27, 28, 30, 31, 37, 39, 42]\n",
    "facility_codes = [10, 18, 19, 20, 21, 22, 33,34, 35, 36, 38, 41, 43, 44, 48, 50, 51, 53, 55, 56, 59, 60, 62, 64]\n",
    "sanitary_codes = [2, 8, 16, 40, 45, 46, 47, 49, 52, 54]\n",
    "staff_codes = [1, 3, 7, 9, 25, 57, 58]\n",
    "unknown_codes = [4, 5, 6, 24, 29, 32, 61, 63, 70]\n",
    "\n",
    "codes = [food_codes, facility_codes, sanitary_codes, staff_codes, unknown_codes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b227d414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings for conversion\n",
    "mapping = create_mapping(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29c494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapped_inspections_before_change = data['violation Codes'].apply(encode_violations, mapping=before_mapping)\n",
    "mapped_inspections = data['violation Codes'].apply(encode_violations, mapping=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7472a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add additional column with violation codes by our general categories\n",
    "data = data.merge(mapped_inspections, left_index=True, right_index=True, suffixes=('', ' Generalized'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff350a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Food', 'Facility conditions', 'Sanitary conditions', 'Staff', 'Other']\n",
    "plot_violations_stacked_bars(data, '', violation_column='violation Codes Generalized', max_violation_code=5, xticks=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8582b5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig,ax=plt.subplots(2,2,figsize=(15,16))\n",
    "data.risk.value_counts().plot(kind='bar',color=['red','yellow','green'],ax=ax[0,0])\n",
    "ax[0,0].tick_params(axis='x',labelrotation=360)\n",
    "ax[0,0].set_title(\"The counts of Risk\",size=20)\n",
    "ax[0,0].set_ylabel('counts',size=18)\n",
    "\n",
    "\n",
    "data.groupby(['inspection_year','risk'])['inspection_id'].agg('count').unstack('risk').plot(ax=ax[0,1],color=['red','yellow','green'])\n",
    "ax[0,1].legend(loc=0, ncol=1, fontsize=14,bbox_to_anchor=(1.15,0.75))\n",
    "ax[0,1].set_title(\"The counts of Risk by year\",size=20)\n",
    "ax[0,1].set_ylabel('counts',size=18)\n",
    "\n",
    "data.groupby(['inspection_month','risk'])['inspection_id'].agg('count').unstack('risk').plot(ax=ax[1,0],color=['red','yellow','green'])\n",
    "ax[1,0].legend(loc=0, ncol=1, fontsize=14,bbox_to_anchor=(-0.25,0.75))\n",
    "ax[1,0].set_title(\"The counts of Risk by month\",size=20)\n",
    "ax[1,0].set_ylabel('counts',size=18)\n",
    "\n",
    "sns.scatterplot(x='longitude',y='latitude',hue='risk' ,data=data, ax=ax[1,1])\n",
    "ax[1,1].set_title(\"The distribution of inspections by risk\",size=20)\n",
    "ax[1,1].set_xlabel('Longitude')\n",
    "ax[1,1].set_ylabel('Latitude')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381e9c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d75077",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_risk_sample=data[data.risk=='Risk 1 (High)'].sample(2500)\n",
    "Long=data_risk_sample.longitude.mean()\n",
    "Lat=data_risk_sample.latitude.mean()\n",
    "risk1_map=folium.Map([Lat,Long],zoom_start=12)\n",
    "\n",
    "risk1_distribution_map=plugins.MarkerCluster().add_to(risk1_map)\n",
    "for lat,lon,label in zip(data_risk_sample.latitude,data_risk_sample.longitude,data_risk_sample['dba_name']):\n",
    "    folium.Marker(location=[lat,lon],icon=None,popup=label).add_to(risk1_distribution_map)\n",
    "risk1_map.add_child(risk1_distribution_map)\n",
    "\n",
    "risk1_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03900f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_risk_sample=data[data.risk=='Risk 2 (Medium)'].sample(2500)\n",
    "Long=data_risk_sample.longitude.mean()\n",
    "Lat=data_risk_sample.latitude.mean()\n",
    "risk2_map=folium.Map([Lat,Long],zoom_start=12)\n",
    "\n",
    "risk2_distribution_map=plugins.MarkerCluster().add_to(risk2_map)\n",
    "for lat,lon,label in zip(data_risk_sample.latitude,data_risk_sample.longitude,data_risk_sample['dba_name']):\n",
    "    folium.Marker(location=[lat,lon],icon=None,popup=label).add_to(risk2_distribution_map)\n",
    "risk2_map.add_child(risk1_distribution_map)\n",
    "\n",
    "risk2_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6099f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_risk_sample=data[data.risk=='Risk 3 (Low)'].sample(2500)\n",
    "Long=data_risk_sample.longitude.mean()\n",
    "Lat=data_risk_sample.latitude.mean()\n",
    "risk3_map=folium.Map([Lat,Long],zoom_start=12)\n",
    "\n",
    "risk3_distribution_map=plugins.MarkerCluster().add_to(risk3_map)\n",
    "for lat,lon,label in zip(data_risk_sample.latitude,data_risk_sample.longitude,data_risk_sample['dba_name']):\n",
    "    folium.Marker(location=[lat,lon],icon=None,popup=label).add_to(risk3_distribution_map)\n",
    "risk3_map.add_child(risk1_distribution_map)\n",
    "\n",
    "risk3_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1df2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf720ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map results to numerical scores\n",
    "result_scores = {'Pass': 1, 'Fail': 0, 'Pass w/ Conditions': 0.5, 'No Entry': 0.5, 'Not Ready': 0.5, 'Business Not Located': 0,\n",
    "                'Out of Business': 0}\n",
    "\n",
    "# Create a new column 'safety_score' with the scores based on 'results'\n",
    "data['safety_score'] = data['results'].map(result_scores)\n",
    "\n",
    "# Optional: Round the safety score to 2 decimal places\n",
    "data['safety_score'] = data['safety_score'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39a3606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'inspection_year' and calculate the mean safety score for each group\n",
    "grouped_data = data.groupby('inspection_year')['safety_score'].mean().reset_index()\n",
    "\n",
    "# Bar plot of safety scores by inspection_year type\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(grouped_data['inspection_year'], grouped_data['safety_score'], color='orange')\n",
    "plt.xlabel('Zip code')\n",
    "plt.ylabel('Mean Safety Score')\n",
    "plt.title('Mean Safety Score by Inspection Year')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80034749",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_safety_sample=data[data['safety_score'] > 0.8].sample(2500)\n",
    "Long=data_safety_sample.longitude.mean()\n",
    "Lat=data_safety_sample.latitude.mean()\n",
    "safety_map=folium.Map([Lat,Long],zoom_start=12)\n",
    "\n",
    "safety_distribution_map=plugins.MarkerCluster().add_to(safety_map)\n",
    "for lat,lon,label in zip(data_safety_sample.latitude,data_safety_sample.longitude,data_safety_sample['dba_name']):\n",
    "    folium.Marker(location=[lat,lon],icon=None,popup=label).add_to(safety_distribution_map)\n",
    "safety_map.add_child(safety_distribution_map)\n",
    "\n",
    "safety_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeb7ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f611415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the five most frequented facility types\n",
    "top_facility_types = data['facility_type'].value_counts().nlargest(5).index\n",
    "\n",
    "# Create a new column 'facility_type_grouped'\n",
    "data['facility_type_grouped'] = data['facility_type']\n",
    "\n",
    "# Map facility types not in the top five to 'unknown'\n",
    "data.loc[~data['facility_type_grouped'].isin(top_facility_types), 'facility_type_grouped'] = 'Unknown Facility'\n",
    "\n",
    "# Group by 'facility_type' and 'inspection_year', and calculate the mean safety score for each group\n",
    "grouped_data = data.groupby(['facility_type_grouped', 'inspection_year'])['safety_score'].mean().reset_index()\n",
    "\n",
    "# Create a pivot table for better visualization\n",
    "pivot_data = grouped_data.pivot_table(index='facility_type_grouped', columns='inspection_year', values='safety_score')\n",
    "\n",
    "# Plot grouped bar chart for mean safety scores by facility type for each inspection year\n",
    "plt.figure(figsize=(12, 6))\n",
    "pivot_data.plot(kind='bar', cmap='tab20', rot=45, ax=plt.gca())\n",
    "plt.xlabel('Facility Type')\n",
    "plt.ylabel('Mean Safety Score')\n",
    "plt.title('Mean Safety Score by Top Five Facility Types for Each Inspection Year')\n",
    "plt.legend(title='Inspection Year', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac785c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'facility_type' and 'risk', and calculate the mean safety score for each group\n",
    "grouped_data = data.groupby(['facility_type_grouped', 'risk'])['safety_score'].mean().reset_index()\n",
    "\n",
    "# Create a pivot table for better visualization\n",
    "pivot_data = grouped_data.pivot_table(index='facility_type_grouped', columns='risk', values='safety_score')\n",
    "\n",
    "# Plot grouped bar chart for mean safety scores by facility type for each risk category\n",
    "plt.figure(figsize=(12, 6))\n",
    "pivot_data.plot(kind='bar', cmap='tab20', rot=45, ax=plt.gca())\n",
    "plt.xlabel('Facility Type')\n",
    "plt.ylabel('Mean Safety Score')\n",
    "plt.title('Mean Safety Score by Top Five Facility Types for Each Risk Category')\n",
    "plt.legend(title='Risk', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae0bdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 zip codes based on the number of inspections\n",
    "top_zip_codes = data['zip'].value_counts().nlargest(10).index\n",
    "\n",
    "# Filter the data to include only the top 10 zip codes\n",
    "filtered_data = data[data['zip'].isin(top_zip_codes)]\n",
    "\n",
    "# Group by 'zip' and 'inspection_year', and calculate the mean safety score for each group\n",
    "grouped_data = filtered_data.groupby(['zip', 'inspection_year'])['safety_score'].mean().reset_index()\n",
    "\n",
    "# Create a pivot table for better visualization\n",
    "pivot_data = grouped_data.pivot_table(index='zip', columns='inspection_year', values='safety_score')\n",
    "\n",
    "# Plot grouped bar chart for mean safety scores by zip code for each inspection year\n",
    "plt.figure(figsize=(12, 6))\n",
    "pivot_data.plot(kind='bar', cmap='tab20', rot=45, ax=plt.gca())\n",
    "plt.xlabel('Zip Code')\n",
    "plt.ylabel('Mean Safety Score')\n",
    "plt.title('Mean Safety Score by Top 10 Zip Codes for Each Inspection Year')\n",
    "plt.legend(title='Inspection Year', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d39d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'zip' and calculate the mean safety score and facility count based on unique license numbers for each group\n",
    "grouped_data = data.groupby('zip').agg(safety_score=('safety_score', 'mean'),\n",
    "                                       facility_count=('license_', 'nunique')).reset_index()\n",
    "\n",
    "# Convert the 'zip' column to string data type in both DataFrames\n",
    "grouped_data['zip'] = grouped_data['zip'].astype(int)\n",
    "grouped_data['zip'] = grouped_data['zip'].astype(str)\n",
    "\n",
    "# Load the zip code boundaries as a GeoDataFrame\n",
    "zip_code_boundaries = gpd.read_file('Boundaries - ZIP Codes.geojson')\n",
    "\n",
    "# Merge the zip code boundaries and grouped_data DataFrames on the 'zip' column\n",
    "merged_data = zip_code_boundaries.merge(grouped_data, on='zip', how='left')\n",
    "\n",
    "# Create a map centered on Chicago\n",
    "map_chicago = folium.Map(location=[41.8781, -87.6298], zoom_start=11)\n",
    "\n",
    "# Calculate the min and max safety scores for the color scale\n",
    "min_score = merged_data['safety_score'].min()\n",
    "max_score = merged_data['safety_score'].max()\n",
    "\n",
    "# Create a gradient color scheme based on the safety scores\n",
    "colormap = linear.YlOrRd_09.scale(min_score, max_score)\n",
    "\n",
    "# Create a style function to shape the zip code areas on the map with the gradient color scheme\n",
    "def style_function(feature):\n",
    "    safety_score = feature['properties']['safety_score']\n",
    "    return {\n",
    "        'fillColor': colormap(safety_score),\n",
    "        'color': 'black',\n",
    "        'weight': 1,\n",
    "        'fillOpacity': 0.7\n",
    "    }\n",
    "\n",
    "# Create a GeoJSON layer for the zip code boundaries with the style function and tooltip\n",
    "folium.GeoJson(merged_data, \n",
    "               tooltip=folium.GeoJsonTooltip(fields=['zip', 'safety_score', 'facility_count'], \n",
    "                                             aliases=['Zip Code', 'Mean Safety Score', 'Facility Count'], \n",
    "                                             labels=True),\n",
    "               style_function=style_function).add_to(map_chicago)\n",
    "\n",
    "# Add the color scale to the map\n",
    "colormap.caption = 'Safety Score'\n",
    "map_chicago.add_child(colormap)\n",
    "\n",
    "# Add title to the map\n",
    "title_html = '''\n",
    "             <h3 align=\"center\" style=\"font-size:16px\"><b>Safety Score by Zip Code</b></h3>\n",
    "             '''\n",
    "map_chicago.get_root().html.add_child(folium.Element(title_html))\n",
    "\n",
    "    \n",
    "    \n",
    "# Display the map\n",
    "map_chicago\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31843cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for specific criteria \n",
    "filtered_data = data[\n",
    "    (data['facility_type'] == 'Restaurant') &\n",
    "    (data['results'] == 'Pass') &\n",
    "    (data['zip'].isin(zip_code_boundaries['zip'])) &\n",
    "    (data['inspection_year'] >= 2023)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47675d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a map centered on Chicago\n",
    "map_chicago = folium.Map(location=[41.8781, -87.6298], zoom_start=11)\n",
    "\n",
    "# Add facility locations to the map for the selected zip codes\n",
    "filtered_facilities = filtered_data.sample(150)\n",
    "facilities_map = plugins.MarkerCluster().add_to(map_chicago)\n",
    "for lat, lon, label in zip(filtered_facilities.latitude, filtered_facilities.longitude, filtered_facilities['dba_name']):\n",
    "    folium.Marker(location=[lat, lon], icon=None, popup=label).add_to(map_chicago)\n",
    "\n",
    "# Create a GeoJSON layer for the zip code boundaries with the style function and tooltip\n",
    "folium.GeoJson(merged_data,\n",
    "               tooltip=folium.GeoJsonTooltip(fields=['zip', 'safety_score', 'facility_count'],\n",
    "                                             aliases=['Zip Code', 'Mean Safety Score', 'Facility Count'],\n",
    "                                             labels=True),\n",
    "               style_function=style_function).add_to(map_chicago)\n",
    "\n",
    "# Add the color scale to the map\n",
    "colormap.caption = 'Safety Score'\n",
    "map_chicago.add_child(colormap)\n",
    "\n",
    "# Add title to the map\n",
    "title_html = '''\n",
    "            <h3 align=\"center\" style=\"font-size:16px\"><b>Safety Score by Zip Code and Restaurants that Passed Inspection in 2023</b></h3>           \n",
    "            '''\n",
    "map_chicago.get_root().html.add_child(folium.Element(title_html))\n",
    "\n",
    "# Display the map\n",
    "map_chicago\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e53f251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfef256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed data to a CSV file\n",
    "data.to_csv('data_eda.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30075ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a3a7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7965fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset \n",
    "data = pd.read_csv('data_eda.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd47f26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the DataFrame to inspect the data\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaa2278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'inspection_type' column into dummy variables using one-hot encoding\n",
    "data = pd.get_dummies(data, columns=['inspection_type'], prefix='', prefix_sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b9d983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'inspection_type' column into dummy variables using one-hot encoding\n",
    "data = pd.get_dummies(data, columns=['facility_type_grouped'], prefix='', prefix_sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6864bdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'inspection_type' column into dummy variables using one-hot encoding\n",
    "risk_encoded = pd.get_dummies(data['risk'], prefix='risk')\n",
    "data = pd.concat([data, risk_encoded], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5a4ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the lengths of violation codes lists\n",
    "list_lengths = []\n",
    "\n",
    "# Loop through each row in the DataFrame\n",
    "for index, row in data.iterrows():\n",
    "    # Get the list of violation codes for the current row\n",
    "    violation_codes_list = row['violation Codes']\n",
    "    \n",
    "    # Calculate the length of the list and append it to the list_lengths\n",
    "    list_length = len(violation_codes_list)\n",
    "    list_lengths.append(list_length)\n",
    "\n",
    "# Create a new column in the DataFrame to store the list lengths\n",
    "data['violation_codes_length'] = list_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7206f1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'violations' is the name of the column containing the violation codes\n",
    "# Replace 'violations' with the actual name of your column\n",
    "\n",
    "food_codes = [11, 12, 13, 14, 15, 17, 23, 26, 27, 28, 30, 31, 37, 39, 42]\n",
    "facility_codes = [10, 18, 19, 20, 21, 22, 33, 35, 36, 38, 41, 43, 44, 48, 50, 51, 53, 55, 56, 59, 60, 62]\n",
    "sanitary_codes = [2, 8, 16, 40, 45, 46, 47, 49, 52, 54]\n",
    "staff_codes = [1, 3, 7, 9, 25, 57, 58]\n",
    "unknown_codes = [4, 5, 6, 24, 29, 32, 61, 63]\n",
    "\n",
    "codes_violation = [food_codes, facility_codes, sanitary_codes, staff_codes, unknown_codes]\n",
    "\n",
    "# Function to safely evaluate and convert the 'violation Codes' string to a list\n",
    "def safe_eval(code_str):\n",
    "    try:\n",
    "        return ast.literal_eval(code_str)\n",
    "    except (SyntaxError, ValueError):\n",
    "        return []\n",
    "\n",
    "# Function to count the violations for each row based on the codes\n",
    "def count_violations(row):\n",
    "    # Convert 'violation Codes' string to a list of integers\n",
    "    violation_codes = safe_eval(row['violation Codes'])\n",
    "    \n",
    "    count_per_group = []\n",
    "    for group_codes in codes_violation:\n",
    "        count_per_group.append(sum(code in group_codes for code in violation_codes))\n",
    "    \n",
    "    return pd.Series(count_per_group, index=['food', 'facility', 'sanitary', 'staff', 'unknown'])\n",
    "\n",
    "# Apply the count_violations function to the first 10 rows of the DataFrame 'data'\n",
    "data[['violation_food', 'violation_facility', 'violation_sanitary', 'violation_staff', 'violation_unknown']] = data.apply(count_violations, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86933a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a threshold for identifying outliers\n",
    "violation_threshold = 100\n",
    "\n",
    "# Identify outlier violation codes\n",
    "outlier_violations = data['violation Codes'].value_counts()[data['violation Codes'].value_counts() < violation_threshold].index\n",
    "\n",
    "# Drop rows with outlier violation codes\n",
    "data = data[~data['violation Codes'].isin(outlier_violations)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2d63f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to keep only 'Pass' and 'Fail' rows\n",
    "data = data[data['results'].isin(['Pass', 'Fail'])]\n",
    "\n",
    "# Map 'Pass' and 'Fail' to 1 and 0, respectively\n",
    "data['results'] = data['results'].map({'Pass': 1, 'Fail': 0})\n",
    "\n",
    "data['results'] = data['results'] .astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eb7c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['risk_Risk 1 (High)', 'risk_Risk 2 (Medium)','risk_Risk 3 (Low)',\n",
    "                    'inspection_year', 'inspection_month',\n",
    "                    \"Children's Services Facility\", 'Grocery Store', 'Restaurant', 'School','Unknown Facility',\n",
    "                    'Canvass', 'Complaint', 'Consultation', 'No Entry', 'Non-Inspection', 'Out Of Business', 'Recent Inspection',\n",
    "                    'Suspected Food Poisoning', 'Tag Removal', 'Task Force', 'Unknown', \n",
    "                    'violation_food', 'violation_facility', 'violation_sanitary', 'violation_staff', 'violation_unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990c4e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into target variable (safety_score) and features\n",
    "X = data[selected_features]\n",
    "\n",
    "y = data['results']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature Scaling (Standardization)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1e260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Decision Tree Regression\n",
    "decision_tree_model = DecisionTreeRegressor(max_depth=3, random_state=42)\n",
    "decision_tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a2c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Random Forest Regression\n",
    "random_forest_model = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "random_forest_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766cdf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Logistic Regression\n",
    "logistic_regression_model = LogisticRegression()\n",
    "logistic_regression_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e21eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4: KNN Regression model\n",
    "knn_model = KNeighborsRegressor(n_neighbors=7)\n",
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd81742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 5: Bagging Regression model\n",
    "bagging_model = BaggingRegressor(n_estimators=10, random_state=42)\n",
    "bagging_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad486dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "\n",
    "# Function to calculate classification metrics\n",
    "def calculate_classification_metrics(model, X, y_true):\n",
    "    y_pred = model.predict(X)     \n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "   \n",
    "    return mse,r2\n",
    "\n",
    "decision_tree_mse, decision_tree_r2 = calculate_classification_metrics(decision_tree_model, X_test, y_test)\n",
    "random_forest_mse, random_forest_r2 = calculate_classification_metrics(random_forest_model, X_test, y_test)\n",
    "logistic_regression_mse,logistic_regression_r2 = calculate_classification_metrics(logistic_regression_model, X_test, y_test)\n",
    "knn_model_mse,  knn_model_r2 = calculate_classification_metrics(knn_model, X_test, y_test)\n",
    "bagging_model_mse, bagging_model_r2 = calculate_classification_metrics(bagging_model, X_test, y_test)\n",
    "\n",
    "# Display the evaluation metrics for each model\n",
    "print(\"Decision Tree Regression:\")\n",
    "print(f\"MSE: {decision_tree_mse:.4f}\")\n",
    "print(f\"R2: {decision_tree_r2:.4f}\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Random Forest Regression:\")\n",
    "print(f\"MSE: {random_forest_mse:.4f}\")\n",
    "print(f\"R2: {random_forest_r2:.4f}\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Logistic Regression:\")\n",
    "print(f\"MSE: {logistic_regression_mse:.4f}\")\n",
    "print(f\"R2: {logistic_regression_r2:.4f}\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"KNN Model:\")\n",
    "print(f\"MSE: {knn_model_mse:.4f}\")\n",
    "print(f\"R2: {knn_model_r2:.4f}\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Bagging Model:\")\n",
    "print(f\"MSE: {bagging_model_mse:.4f}\")\n",
    "print(f\"R2: {bagging_model_r2:.4f}\")\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debf9d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bff7772",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Based on the comprehensive evaluation of the models mentioned earlier and their performance metrics, we have selected the Random Forest, Bagging, and KNN Neighbors models for further refinement using GridSearchCV and cross-validation. These models have shown promising results during the initial evaluation, making them ideal candidates for fine-tuning and optimizing their hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf22e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The hyperparameter grids for each model\n",
    "random_forest_param_grid = {\n",
    "    'n_estimators': [10, 15, 20],\n",
    "    'max_depth': [2, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "bagging_param_grid = {\n",
    "    'n_estimators': [10, 15, 20],  \n",
    "    'max_samples': [0.5, 0.7, 0.9],  \n",
    "    'max_features': [0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['ball_tree', 'kd_tree'],\n",
    " }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05aeeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform GridSearchCV for each model\n",
    "random_forest_gridsearch = GridSearchCV(RandomForestRegressor(), random_forest_param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "bagging_gridsearch = GridSearchCV(BaggingRegressor(), bagging_param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "knn_gridsearch = GridSearchCV(KNeighborsRegressor(), knn_param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the models to the training data\n",
    "random_forest_gridsearch.fit(X_train, y_train)\n",
    "bagging_gridsearch.fit(X_train, y_train)\n",
    "knn_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "# Perform cross-validation using the best estimator for each model\n",
    "cv_scores_rf = cross_val_score(random_forest_gridsearch.best_estimator_, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_scores_bagging = cross_val_score(bagging_gridsearch.best_estimator_, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_scores_knn = cross_val_score(knn_gridsearch.best_estimator_, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Print the cross-validation scores for each model\n",
    "print(\"Random Forest Cross-Validation Scores:\", cv_scores_rf)\n",
    "print(\"Bagging Cross-Validation Scores:\", cv_scores_bagging)\n",
    "print(\"KNN Cross-Validation Scores:\", cv_scores_knn)\n",
    "\n",
    "# Get the best MSE for each model\n",
    "best_rf_mse = -random_forest_gridsearch.best_score_\n",
    "best_bagging_mse = -bagging_gridsearch.best_score_\n",
    "best_knn_mse = -knn_gridsearch.best_score_\n",
    "\n",
    "# Print the best MSE for each model\n",
    "print(\"Best Random Forest MSE:\", best_rf_mse)\n",
    "print(\"Best Bagging MSE:\", best_bagging_mse)\n",
    "print(\"Best KNN MSE:\", best_knn_mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dce923b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc8d245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0310f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
